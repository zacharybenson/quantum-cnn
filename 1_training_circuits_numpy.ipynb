{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aded9b1",
   "metadata": {},
   "source": [
    "#  Training Sequential Circuits with NumPy\n",
    "This notebook shows the expands upon the sequential circuits structure <br>\n",
    "and optimize the circuit using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6026c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pennylane\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a45d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates.embeddings import AmplitudeEmbedding\n",
    "from model import Conv1DLayer, PoolingLayer, unitarity_conv1d, unitarity_pool, unitarity_toffoli\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3e29e",
   "metadata": {},
   "source": [
    "# Defining the Quantum device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d96393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify how many wires will be used\n",
    "num_wires = 12\n",
    "num_ancilla = 4\n",
    "num_work_wires = num_wires - num_ancilla\n",
    "\n",
    "#Specify what type of device you are using.\n",
    "#device_type = 'default.qubit'\n",
    "#device_type = 'braket.local.qubit'\n",
    "device_type = 'lightning.qubit'\n",
    "\n",
    "\n",
    "#Initialize Device\n",
    "dev = qml.device(device_type, wires=num_wires)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e41c6",
   "metadata": {},
   "source": [
    "# Defining circuit to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae786b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit(num_wires, num_ancilla):\n",
    "    @qml.qnode(dev, interface='autograd', diff_method ='adjoint')\n",
    "    def func(inputs, params): \n",
    "        work_wires = list(range(num_wires - num_ancilla))\n",
    "        ancilla_wires = list(range(len(work_wires),num_wires))\n",
    "\n",
    "        # Data Embedding Layer\n",
    "        AmplitudeEmbedding(inputs , wires=work_wires , normalize=True)\n",
    "\n",
    "        # Hidden Layers\n",
    "        work_wires , params = Conv1DLayer(unitarity_conv1d , 15)(work_wires , params)\n",
    "        work_wires , params = PoolingLayer(unitarity_pool , 2)(work_wires , params)\n",
    "        work_wires , params = Conv1DLayer(unitarity_conv1d , 15)(work_wires , params)\n",
    "        work_wires , params = PoolingLayer(unitarity_pool , 2)(work_wires , params)\n",
    "\n",
    "        #Toffili Structure\n",
    "        unitarity_toffoli(work_wires,ancilla_wires)\n",
    "\n",
    "        return [qml.expval(qml.PauliZ(wire)) for wire in ancilla_wires]\n",
    "    return func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57e7d6",
   "metadata": {},
   "source": [
    "# Import training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0eec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "batch_size = 32\n",
    "embedding_size = 2**num_work_wires\n",
    "labels = [0,1,2,3]  #,4,5,6,7]\n",
    "num_labels = len(labels)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((16,16)),\n",
    "    transforms.Lambda(lambda x: torch.reshape(x, (-1,))),\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='./dataset/minst/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='./dataset/minst/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "#Filter for classes \n",
    "train_idx = [i for i, y in enumerate(train_data.targets) if y in labels]\n",
    "train_data = torch.utils.data.Subset(train_data, train_idx)\n",
    "\n",
    "test_idx = [i for i, y in enumerate(test_data.targets) if y in labels]\n",
    "test_data = torch.utils.data.Subset(test_data, test_idx)\n",
    "\n",
    "# Pytorch loader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "# Pytorch loader\n",
    "test_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    drop_last = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3d110",
   "metadata": {},
   "source": [
    "# Defining Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe6330fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as anp \n",
    "\n",
    "def cross_entropy(targets, predictions):\n",
    "    loss = 0\n",
    "    for target, prediction in zip(targets, predictions):\n",
    "        c_entropy = target * (anp.log(prediction[target])) + (1 - target) * anp.log(1 - prediction[1 - target])\n",
    "        loss = loss + c_entropy\n",
    "    return loss\n",
    "    \n",
    "def loss(params, data, targets):\n",
    "    predictions = [circuit(num_wires, num_ancilla)(x,params) for x in data]\n",
    "    return cross_entropy(labels, predictions)\n",
    "        \n",
    "    \n",
    "def label(q_input):\n",
    "    labels = []\n",
    "    for val in q_input:\n",
    "        l = np.argmax(val) \n",
    "        labels.append(l)\n",
    "    return labels\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    acc = 0\n",
    "    predicted_labels = label(predictions)\n",
    "    for l, p in zip(labels, predicted_labels):\n",
    "        if np.abs(l - p) < 1:\n",
    "            acc = acc + 1\n",
    "    return acc / len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdcaf00",
   "metadata": {},
   "source": [
    "# Defining Parameters and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c321aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 8\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "train_samples = len(train_data)\n",
    "batches = train_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8923dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.random.normal(loc=0.0, scale=1.0, size = 357)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c03e7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8378d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = qml.AdamOptimizer(stepsize=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55e8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f19685e56d94cae919811c60393f91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/773 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | Loss: -3.327185 | Train accuracy: 0.218750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5bb1aae0cd4cf19b2610f416bc6e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/773 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 | Loss: -2.721115 | Train accuracy: 0.125000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326a5113e72d4ed09468bfabdd085ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/773 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 | Loss: -4.233556 | Train accuracy: 0.250000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f56006d576b410397beebe694eed3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/773 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 | Loss: -2.914836 | Train accuracy: 0.312500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4547c4935a924fb0ba1b8aa3ee4a6695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/773 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 | Loss: -3.311690 | Train accuracy: 0.093750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e61055c4514d91adfb3dae4de12af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/773 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6 | Loss: -3.517539 | Train accuracy: 0.218750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a1d9096b6944b2b27b86084b7563ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/773 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "import traceback\n",
    "history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for batch, i in zip(train_loader,trange(batches)):\n",
    "        \n",
    "        data = batch[0]\n",
    "        target = batch[1]      \n",
    "                \n",
    "        try:\n",
    "            params, cost = opt.step_and_cost(lambda v: loss(v,data,target),\n",
    "                                                      params)\n",
    "        except Exception:\n",
    "            print(traceback.format_exc())\n",
    "               \n",
    "    history.append(res)\n",
    "    predicted_train = label([circuit(num_wires, num_ancilla)(x,params) for x in data])\n",
    "    accuracy_train = accuracy(predicted_train , target)\n",
    "    cost = loss(params, data, target)    \n",
    "    res = [epoch + 1, cost, accuracy_train]\n",
    "    print(\n",
    "    \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f}\".format(\n",
    "        *res\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37caaf1f",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f99c7df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33914/1878667249.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_test = label([circuit(x,params) for x in X_test])\n",
    "accuracy_test = accuracy(predicted_test,Y_test)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
